## 1. 알약을 사진으로 검색(가제) 

**설명** : 알약의 사진을 찍으면 모양, 색상, 각인 등을 통해서 어떤 약인지를 알려준다.

**검색 결과?** : 

국내 플랫폼에서는, 네이버나 약학 정보원에서 모양, 색상, 각인 등으로 약을 검색할 수 있긴 한데, 사진을 인식할 수 있는 기능은 국내나 국외나 상용화 된 것이 없다.

타이완에서 약 96% 정확도를 보여주는 딥러닝 모델을 만든 사례가 있고, 어디 석사 졸업 논문이 있긴 하다.
그리고 뒤에 전용 배경 이미지를 깔아서 사진 찍어서 인식하는 애들이 있긴 하다.(13년에 만든건데 이제 앱스토어에 없더라.)

(우리가 좀 더 알아보긴 해야함. 무슨 기술 썼는지, 어떻게 구현했는지 이걸 알아야 우리가 차별화 시킬수가 있다. 왜 상용화를 못하고 있는지도 알 수 있다.)

이런 식으로 논문 수준으로는 있는데, 왜 상용화가 안됐을까?

**기타** : 딥러닝으로 이미지 처리를 해야될 것 같긴 한데, 팀원들 모두 딥러닝 경험이 없어서 난이도가 꽤 있을 것 같아서 학기 내에 할 수 있을지 잘 모르겠다. 

논문들이 나오긴 하는데, 상용화가 안됐고, 세명다 딥러닝 경험이 없어서 봐도 이게 뭔지 모르겠다. 근데 일단 주제가 아쉬워서 가져와봤다.

그리고 만약 이걸로 주제가 결정돼서 진행을 한다면, 학습을 위한 알약 이미지들이 있어야될텐데, 그걸 합법적으로 구할 수 있을지 모르겟다.



## 2. 강의 영상을 텍스트 스크립트로 요약(가제)

**설명**: 강의 영상을 자막화해서 그 내용을 정리 요약해준다. 요약된 스크립트의 내용을 클릭하면, 원본 영상 내에서 해당 내용의 시간을 알려주고, 영상의 해당 부분의 스크린샷을 보여준다.

**검색 결과** : 이런식으로 구현된게 없습니다. 영상 요약 쪽으로 검색하면, 전체 영상에서 핵심적이거나 가장 중요한 한 부분을 추측해서 뽑아주는 정도는 있는데, 그런건 핫클립이나 섬네일 용으로나 적합하다. 

근데 강의 영상은 그런 식으로 다른 부분을 쳐내버리면 안된다. 강의 내용 전체에서 중요하지 않은 부분은 거의 없기 때문. 그래서 기존의 영상 요약 기술들과는 좀 방향성이 다르다.

**기타** : 음성 인식을 하고, 자연어 처리를 해야될 것 같다. 이미지랑 시간 알려주는건 크게 어렵지 않을 것 같다.
음성 인식이야 뭐 널려 있는 API가져다가 써도 문제 없지 않을까 싶다.



## 3. 영상 속 말 더듬는 부분 자동 편집(가제)

**설명** : 위랑 조금 비슷한데 방향성이 좀 다르다. 강의, 강좌 뿐 아니라 개인이 설명영상 등 영상 찍어놓은 것들을 보면, 말을 더듬거나 했던 말을 반복하거나, 장면 전환하는데 무의미하게 멍때리거나 이런 경우가 있다. 그런 것들을 다 쳐내주면 보는 입장에서 훨씬 깔끔하고 전달력이 높아질 것이다.

**검색 결과**: 보통 전문 유튜버나 이런 사람들은 편집자를 써버리기 때문에 그 편집자들이 알아서 잘라 붙혀주고 하는데, 일반 사용자들은 그런게 없어요. 



## 4. 학습용 마인드맵 자동 제작 소프트웨어

**설명** : 전공책이나 강의 PDF 등등 학습자료를 분석해서 그걸 마인드 맵으로 만들어준다. 마인드 맵에는 기술, 용어들에 대한 개념 및 정의를 설명한 것들을 정리한 노드가 있고, 연관된 개념들을 연결해준다.

**검색 결과**: 마인드맵 자동 제작 툴 자체는 있는데, 스트레드 시트라든가 스케줄러 이런 형식이 있는 것들을 마인드맵화 해준다. 요것은 텍스트로만 되어있는 학습 자료를 시각화해서 학습 보조자료로 쓸 수 있게 해주자는 취지라서 확실하게 차별화 할 수 있어 보인다.

